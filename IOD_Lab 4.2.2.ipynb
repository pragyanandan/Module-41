{"cells":[{"cell_type":"markdown","metadata":{"id":"9XIMscuZXR3_"},"source":["<div>\n","<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"_MEq0z1KXR4C"},"source":["## Lab 4.2.2: Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"Izj4LsbrGNc8"},"source":["Moving beyond basic feature selection methods, this lab introduces forward feature selection. Through an iterative process, we progressively include features that contribute to improving the model's adjusted R-squared score. By systematically evaluating the impact of each feature, we aim to construct a regression model that captures the underlying patterns in the data."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Od_2rcZkXR4D"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"mADumyI3XR4G"},"source":["### 5. Forward Feature Selection\n","\n","> Forward Selection: Forward selection is an iterative method in which we start with having no feature in the model. In each iteration, we keep adding the feature which best improves our model till an addition of a new variable does not improve the performance of the model.\n","\n","Create a Regression model using Forward Feature Selection by looping over all the features adding one at a time until there are no improvements on the prediction metric ( R2  and  AdjustedR2  in this case)."]},{"cell_type":"markdown","metadata":{"id":"Ha-2bFwdXR4H"},"source":["#### 5.1 Load Wine Data & Define Predictor and Target"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"dKp1loQLXR4H"},"outputs":[],"source":["## Load the wine quality dataset\n","\n","# Load the wine dataset from csv\n","wine = pd.read_csv('winequality_merged.csv')\n","\n","# define the target variable (dependent variable) as y\n","y = wine['quality']\n","\n","# Take all columns except target as predictor columns\n","predictor_columns = [c for c in wine.columns if c != 'quality']\n","# Load the dataset as a pandas data frame\n","X = pd.DataFrame(wine, columns = predictor_columns)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"_IaxFgFkXR4K"},"outputs":[],"source":["## Create training and testing subsets\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"]},{"cell_type":"markdown","metadata":{"id":"sHGOCW66XR4M"},"source":["#### 5.2 Overview of the code below\n","\n","The external `while` loop goes forever until there are no improvements to the model, which is controlled by the flag `changed` (until is **not** changed).\n","The inner `for` loop goes over each of the features not yet included in the model and calculates the correlation coefficient. If any model improves on the previous best model then the records are updated.\n","\n","#### Code variables\n","- `included`: list of the features (predictors) that were included in the model; starts empty.\n","- `excluded`: list of features that have **not** been included in the model; starts as the full list of features.\n","- `best`: dictionary to keep record of the best model found at any stage; starts 'empty'.\n","- `model`: object of class LinearRegression, with default values for all parameters.\n","\n","#### Methods of the `LinearRegression` object to investigate\n","- `fit()`\n","- `fit.score()`\n","\n","#### Adjusted $R^2$ formula\n","$$Adjusted \\; R^2 = 1 - { (1 - R^2) (n - 1)  \\over n - k - 1 }$$\n","\n","#### Linear Regression [reference](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"LVJY9yXaXR4M"},"outputs":[],"source":["## Flag intermediate output\n","\n","show_steps = True   # for testing/debugging\n","# show_steps = False  # without showing steps"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"vxROsvaIXR4P"},"outputs":[{"name":"stdout","output_type":"stream","text":["Added feature alcohol with R^2 = 0.194 and adjusted R^2 = 0.194\n","Added feature volatile acidity with R^2 = 0.251 and adjusted R^2 = 0.251\n","Added feature sulphates with R^2 = 0.261 and adjusted R^2 = 0.260\n","Added feature residual sugar with R^2 = 0.268 and adjusted R^2 = 0.268\n","Added feature red_wine with R^2 = 0.273 and adjusted R^2 = 0.272\n","Added feature density with R^2 = 0.277 and adjusted R^2 = 0.276\n","Added feature free sulfur dioxide with R^2 = 0.279 and adjusted R^2 = 0.278\n","Added feature total sulfur dioxide with R^2 = 0.282 and adjusted R^2 = 0.281\n","Added feature chlorides with R^2 = 0.283 and adjusted R^2 = 0.282\n","Added feature pH   with R^2 = 0.284 and adjusted R^2 = 0.283\n","Added feature fixed acidity with R^2 = 0.287 and adjusted R^2 = 0.286\n","\n","Resulting features:\n","alcohol, volatile acidity, sulphates, residual sugar, red_wine, density, free sulfur dioxide, total sulfur dioxide, chlorides, pH, fixed acidity\n"]}],"source":["from sklearn.linear_model import LinearRegression\n","\n","# Assuming X_train and y_train are already defined somewhere in your context\n","\n","# start with no predictors\n","included = []\n","# keep track of model and parameters\n","best = {'feature': '', 'r2': 0, 'a_r2': 0}\n","# create a model object to hold the modelling parameters\n","model = LinearRegression()  # create a model for Linear Regression\n","# get the number of cases in the training data\n","n = X_train.shape[0]\n","\n","def calculate_adjusted_r2(r2, n, k):\n","    return 1 - (1 - r2) * (n - 1) / (n - k - 1)\n","\n","while True:\n","    changed = False\n","\n","    # list the features to be evaluated\n","    excluded = list(set(X_train.columns) - set(included))\n","\n","    # for each remaining feature to be evaluated\n","    for new_column in excluded:\n","\n","        # fit the model with the Training data\n","        X_subset = X_train[included + [new_column]]\n","        model.fit(X_subset, y_train)\n","\n","        # calculate the score (R^2 for Regression)\n","        r2 = model.score(X_subset, y_train)\n","\n","        # number of predictors in this model\n","        k = len(included) + 1\n","\n","        # calculate the adjusted R^2\n","        adjusted_r2 = calculate_adjusted_r2(r2, n, k)\n","\n","        # if model improves\n","        if adjusted_r2 > best['a_r2']:\n","            # record new parameters\n","            best = {'feature': new_column, 'r2': r2, 'a_r2': adjusted_r2}\n","            # flag that found a better model\n","            changed = True\n","\n","    # if found a better model after testing all remaining features\n","    if changed:\n","        # update control details\n","        included.append(best['feature'])\n","        excluded.remove(best['feature'])\n","        print('Added feature %-4s with R^2 = %.3f and adjusted R^2 = %.3f' %\n","              (best['feature'], best['r2'], best['a_r2']))\n","    else:\n","        # terminate if no better model\n","        break\n","\n","print('')\n","print('Resulting features:')\n","print(', '.join(included))\n"]},{"cell_type":"markdown","metadata":{"id":"3LCpYCPXl1XK"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","> > > > > > > > > Â© 2024 Institute of Data\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
